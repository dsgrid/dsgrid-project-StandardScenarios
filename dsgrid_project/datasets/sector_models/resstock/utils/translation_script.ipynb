{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What model was used to create these results?\n",
      "resstock\n",
      "You have entered resstock, is that correct? [y/n]\n",
      "y\n",
      "Great!\n",
      "Input the timeseries results file\n",
      "group0.parquet\n",
      "You have entered group0.parquet, is that correct? [y/n]\n",
      "y\n",
      "Great!\n",
      "Input the county lookup table file\n",
      "county_lookup.csv\n",
      "You have entered county_lookup.csv, is that correct? [y/n]\n",
      "y\n",
      "Great!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import toml\n",
    "\n",
    "\n",
    "## User input and directory creation\n",
    "def initialize_timeseries():\n",
    "    print('Input the timeseries results file')\n",
    "    initialize_timeseries.file = input()\n",
    "    print('You have entered '+ initialize_timeseries.file+', is that correct? [y/n]')\n",
    "    def file_input1():\n",
    "        initialize_timeseries.file_answer = input()\n",
    "        if initialize_timeseries.file_answer == 'y':\n",
    "            print('Great!')\n",
    "            return\n",
    "        elif initialize_timeseries.file_answer == 'n':\n",
    "            print(\"Okay. Let's try again.\")\n",
    "            initialize_timeseries()\n",
    "        else: \n",
    "            print(\"Invalid input. Let's try again.\")\n",
    "            print('You have entered '+ initialize_timeseries.file+', is that correct? [y/n]')\n",
    "            file_input1()\n",
    "    file_input1()\n",
    "              \n",
    "def initialize_model():\n",
    "    print('What model was used to create these results?')\n",
    "    initialize_model.model = input()\n",
    "    print('You have entered '+ initialize_model.model+', is that correct? [y/n]')\n",
    "    file_answer = input()\n",
    "    if file_answer == 'y':\n",
    "        if initialize_model.model == 'ResStock' or initialize_model.model =='resstock' or initialize_model.model =='Resstock':\n",
    "            initialize_model.source = [['rld', 'ResStock'], ['null', 'null']]\n",
    "            initialize_model.sector = [['rld', 'Residential'], ['null', 'null']]\n",
    "            initialize_model.model_output = 'ResStock'\n",
    "            initialize_model.sector_output = 'Residential'\n",
    "            print('Great!')\n",
    "            return\n",
    "        elif initialize_model.model == 'Tempo' or initialize_model.model =='tempo' or initialize_model.model =='TEMPO':\n",
    "            initialize_model.source = [['tld', 'TEMPO'], ['null', 'null']]\n",
    "            initialize_model.sector = [['tld', 'Transportation'], ['null', 'null']]\n",
    "            initialize_model.model_output = 'TEMPO'\n",
    "            initialize_model.sector_output = 'Transportation'\n",
    "            print('Great!')\n",
    "            return\n",
    "        elif initialize_model.model == 'ComStock' or initialize_model.model =='comstock' or initialize_model.model =='Comstock':\n",
    "            initialize_model.source = [['cld', 'ComStock'], ['null', 'null']]\n",
    "            initialize_model.sector = [['cld', 'Commercial'], ['null', 'null']]                \n",
    "            initialize_model.model_output = 'ComStock'\n",
    "            initialize_model.sector_output = 'Commercial'\n",
    "            print('Great')\n",
    "            return\n",
    "        else:\n",
    "            print(\"Invalid input. Let's try again.\")\n",
    "            initialize_model()\n",
    "    elif file_answer == 'n':\n",
    "        print(\"Okay. Let's try again.\")\n",
    "        initialize_model()\n",
    "    else: \n",
    "        print(\"Invalid input. Let's try again.\")            \n",
    "        initialize_model()\n",
    "\n",
    "def initialize_county():\n",
    "    print('Input the county lookup table file')\n",
    "    initialize_county.file = input()\n",
    "    print('You have entered '+ initialize_county.file+', is that correct? [y/n]')\n",
    "    def file_input2():\n",
    "        file_answer = input()\n",
    "        if file_answer == 'y':\n",
    "            print('Great!')\n",
    "            return\n",
    "        elif file_answer == 'n':\n",
    "            print(\"Okay. Let's try again.\")\n",
    "            initialize_county()\n",
    "        else: \n",
    "            print(\"Invalid input. Let's try again.\")\n",
    "            print('You have entered '+ initialize_county.file+', is that correct? [y/n]')\n",
    "            file_input2()\n",
    "    file_input2()\n",
    " \n",
    " # For local path directions   \n",
    "def cleardir():\n",
    "    cleardir.path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/datasets/sector_models/resstock'\n",
    "    cleardir.dimension_path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/datasets/sector_models/resstock/dimensions'\n",
    "    cleardir.supplemental_dimension_path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/datasets/sector_models/resstock/dimensions/supplemental'\n",
    "    cleardir.sources_path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/datasets/sector_models/resstock/sources'\n",
    "    cleardir.utils_path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/datasets/sector_models/resstock/utils'\n",
    "    cleardir.dimension_mappings_path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/dimension_mappings'\n",
    "    cleardir.sources_supplemental_path = '/Users/nsandova/dsgrid-project-StandardScenarios/dsgrid_project/datasets/sector_models/resstock/sources/supplemental_dimensions'\n",
    "    \n",
    "    isdir1 = os.path.isdir(cleardir.dimension_path)\n",
    "    if isdir1 == True:\n",
    "        shutil.rmtree(cleardir.dimension_path)\n",
    "        os.mkdir(cleardir.dimension_path)\n",
    "    else:\n",
    "        os.mkdir(cleardir.dimension_path)\n",
    "    \n",
    "    isdir2 = os.path.isdir(cleardir.dimension_mappings_path)\n",
    "    if isdir2 == True:\n",
    "        shutil.rmtree(cleardir.dimension_mappings_path)\n",
    "        os.mkdir(cleardir.dimension_mappings_path)\n",
    "    else:\n",
    "        os.mkdir(cleardir.dimension_mappings_path)\n",
    "    \n",
    "    isdir3 = os.path.isdir(cleardir.supplemental_dimension_path)\n",
    "    if isdir3 == True:\n",
    "        shutil.rmtree(cleardir.supplemental_dimension_path)\n",
    "        os.chdir(cleardir.sources_path)\n",
    "        return\n",
    "    else:\n",
    "        os.chdir(cleardir.sources_path)\n",
    "        return\n",
    "\n",
    "# Need to build out S3 directions \n",
    "\n",
    "# Run functions\n",
    "initialize_model()\n",
    "initialize_timeseries()\n",
    "initialize_county()\n",
    "cleardir()\n",
    "\n",
    "##Translate inputted file into appropriate dataframes\n",
    "# Change to sources directory\n",
    "os.chdir(cleardir.sources_path)\n",
    "\n",
    "# Read parquet file\n",
    "timeseries = pq.read_table(initialize_timeseries.file)\n",
    "\n",
    "# Translate parquet file into a dataframe\n",
    "timeseries_df = timeseries.to_pandas()\n",
    "\n",
    "## Create enduse dataframe\n",
    "column = list(timeseries_df.columns)\n",
    "enduse = [s for s in column if s.startswith('electricity') or s.startswith('fuel_oil') or s.startswith('natural_gas') or s.startswith('propane')or s.startswith('wood_heating')]\n",
    "\n",
    "# Create name column for enduse dataframe\n",
    "enduse_short = []\n",
    "for i in enduse:\n",
    "    enduse_partition = i.rpartition('_')[0]\n",
    "    enduse_short.append(enduse_partition)\n",
    "    \n",
    "# Create index column for enduse dataframe\n",
    "num = len(enduse)\n",
    "id = []\n",
    "for i in range(0,num):\n",
    "    id.append(i)\n",
    "\n",
    "# Create fuel type column for enduse dataframe\n",
    "fuel_type_scrape = []\n",
    "for i in enduse:  \n",
    "    fuel_type_partition = i.partition('_')[0]\n",
    "    fuel_type_scrape.append(fuel_type_partition)\n",
    "    \n",
    "fuel_type_1 = []\n",
    "for entry in fuel_type_scrape:\n",
    "    fuel = entry.replace('fuel','fuel oil')\n",
    "    fuel_type_1.append(fuel)\n",
    "   \n",
    "fuel_type_2 = []\n",
    "for entry in fuel_type_1:\n",
    "    fuel = entry.replace('natural','natural gas')\n",
    "    fuel_type_2.append(fuel)\n",
    "\n",
    "fuel_type_final = []\n",
    "for entry in fuel_type_2:\n",
    "    fuel = entry.replace('wood','wood heating')\n",
    "    fuel_type_final.append(fuel)\n",
    "\n",
    "# Create units column for enduse data frame\n",
    "units = []\n",
    "for i in enduse:  \n",
    "    unit_partition = i.rpartition('_')[-1]\n",
    "    units.append(unit_partition)\n",
    "\n",
    "# Combine id, name, fuel type, and units into final enduse dataframe\n",
    "enduse_final = {'id':id,'name':enduse_short,'fuel type': fuel_type_final, 'units': units}\n",
    "enduse_final_df = pd.DataFrame(enduse_final)\n",
    "\n",
    "\n",
    "## Create county dataframe\n",
    "county_df = pd.read_csv(initialize_county.file)\n",
    "\n",
    "# Pull relevant columns for county dataframe\n",
    "id = county_df.loc[:,\"long_name\"]\n",
    "fips = county_df.loc[:,\"fips\"]\n",
    "county = county_df.loc[:,'county_name']\n",
    "state = county_df.loc[:,'state_abbr']\n",
    "\n",
    "# Combine columns into final county dataframe\n",
    "county_csv = {'id':id,'name':county,'state': state, 'fips':fips}\n",
    "county_final_df = pd.DataFrame(county_csv)\n",
    "\n",
    "## Create final sources dataframe\n",
    "sources_df = pd.DataFrame(initialize_model.source, columns = ['id','name'])\n",
    "sources_df.drop([1], axis=0, inplace = True)\n",
    "\n",
    "## Create final sectors dataframe\n",
    "sectors_df = pd.DataFrame(initialize_model.sector, columns = ['id','name'])\n",
    "sectors_df.drop([1], axis=0, inplace = True)\n",
    "\n",
    "## Create model year dataframe\n",
    "model_year = list(range(2010, 2052, 2))\n",
    "model_year_csv = {'id':model_year,'name':model_year}\n",
    "model_year_df = pd.DataFrame(model_year_csv)\n",
    "\n",
    "## Create scenario dataframe\n",
    "scenarios_id = [\"reference\"]\n",
    "scenarios_name = [\"Reference\"]\n",
    "scenarios_csv = {'id':scenarios_id,'name':scenarios_name}\n",
    "scenarios_df = pd.DataFrame(scenarios_csv)\n",
    "\n",
    "## Create subsectors dataframe\n",
    "subsectors_df = pd.read_csv(\"Geometry_Building_Type_ACS.tsv\", sep='\\t')\n",
    "subsectors_column = list(subsectors_df.columns)\n",
    "del subsectors_column[10:13]\n",
    "del subsectors_column[0]\n",
    "\n",
    "subsectors_scrape = []\n",
    "for i in subsectors_column:  \n",
    "    subsectors_partition = i.partition('=')[-1]\n",
    "    subsectors_scrape.append(subsectors_partition)\n",
    "\n",
    "subsectors_num = len(subsectors_scrape)\n",
    "subsectors_id = []\n",
    "for i in range(0,subsectors_num):\n",
    "    subsectors_id.append(i)\n",
    "\n",
    "subsectors_csv = {'id':subsectors_id,'name':subsectors_scrape}\n",
    "subsectors_df = pd.DataFrame(subsectors_csv)\n",
    "\n",
    "## Create scenario dataframe\n",
    "weather_id = [\"2012\"]\n",
    "weather_name = [\"2012\"]\n",
    "weather_years_csv = {'id':weather_id,'name':weather_name}\n",
    "weather_years_df = pd.DataFrame(weather_years_csv)\n",
    "\n",
    "## Create mapping dataframes\n",
    "fips_short = []\n",
    "for i in fips:\n",
    "    fips_partition = i.partition('G')[-1]\n",
    "    fips_short.append(fips_partition)\n",
    "county_mapping = {'from_id':id, 'to_id':fips_short}\n",
    "county_mapping_df = pd.DataFrame(county_mapping)\n",
    "\n",
    "\n",
    "## Create .csv files in output directory\n",
    "# Change to ouput directory\n",
    "os.chdir(cleardir.dimension_path)\n",
    "\n",
    "# Create enduses.csv\n",
    "enduse_final_df.to_csv('enduses.csv', index = False)\n",
    "\n",
    "# Create sources.csv file\n",
    "sources_df.to_csv('sources.csv', index = False)\n",
    "\n",
    "# Create sectors.csv file\n",
    "sectors_df.to_csv('sectors.csv', index = False)\n",
    "\n",
    "# Create county.csv file\n",
    "county_final_df.to_csv('counties.csv', index = False)\n",
    "\n",
    "# Create model_year.csv file\n",
    "model_year_df.to_csv('model_year.csv', index = False)\n",
    "\n",
    "# Create scenarios.csv\n",
    "scenarios_df.to_csv('scenarios.csv', index = False)\n",
    "\n",
    "# Create subsectors.csv\n",
    "subsectors_df.to_csv('subsectors.csv', index = False)\n",
    "\n",
    "# Create subsectors.csv\n",
    "weather_years_df.to_csv('weather_years.csv', index = False)\n",
    "\n",
    "# Change to supplemental directory\n",
    "shutil.copytree(cleardir.sources_supplemental_path, cleardir.supplemental_dimension_path)\n",
    "\n",
    "#Deletes the census region/divison supplemental dimensions .csv files \n",
    "os.chdir(cleardir.supplemental_dimension_path)\n",
    "os.remove(\"census_divisions.csv\")\n",
    "os.remove(\"census_regions.csv\")\n",
    "\n",
    "## Create .toml file\n",
    "# Change to sources directory\n",
    "os.chdir(cleardir.sources_path)\n",
    "\n",
    "# Transform .toml file into a dictionary\n",
    "dimensions_toml = toml.load(\"template.toml\")\n",
    "\n",
    "# Edit toml dictionary with initialize_model function inputs\n",
    "dimensions_toml['dimensions'][1]['description'] = 'dsgrid Standard Scenarios 2021 Sectors;'+ initialize_model.sector_output+' only'\n",
    "dimensions_toml['dimensions'][1]['name'] = 'Standard Scenarios 2021 Sectors-'+initialize_model.sector_output +'-Only'\n",
    "dimensions_toml['dimensions'][5]['description'] ='dsgrid Standard Scenarios 2021 Data Sources;'+ initialize_model.model_output +' Only\\n'\n",
    "dimensions_toml['dimensions'][5]['name'] = 'Standard Scenarios 2021 DataSourcs -'+initialize_model.model_output +'-Only'\n",
    "\n",
    "# Change to ouput directory\n",
    "os.chdir(cleardir.path)\n",
    "\n",
    "# Create .toml file\n",
    "with open ('dimensions.toml','w') as f:\n",
    "   data = toml.dump(dimensions_toml,f)\n",
    "\n",
    "## Create dimension mapping .csv files\n",
    "# Change to dimension_mappings directory\n",
    "os.chdir(cleardir.dimension_mappings_path)\n",
    "\n",
    "# Create resstock_county_to_dsgrid_county.csv\n",
    "county_mapping_df.to_csv('resstock_county_to_dsgrid_county.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
