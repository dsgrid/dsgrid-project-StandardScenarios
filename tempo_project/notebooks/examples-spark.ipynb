{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18eafc3-823d-4fde-ada2-0d7885af4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/30 15:15:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "data_dir = Path(\"/projects/dsgrid/tempo-project/april-queries/\")\n",
    "dataset_name = \"state_level_simplified\"\n",
    "\n",
    "spark = (\n",
    "            SparkSession.builder\n",
    "            .appName(\"dsgrid\")\n",
    "            .config(\"spark.sql.session.timeZone\", \"EST\")\n",
    "            .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a887e1-7c14-4810-9520-14f25729da3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------+-----------+-------------------+------------+------------------+------------+\n",
      "|state|tempo_project_model_years|  subsector|           time_est|weather_2012|             value|    scenario|\n",
      "+-----+-------------------------+-----------+-------------------+------------+------------------+------------+\n",
      "|   CA|                     2036|phev_pickup|2012-09-28 16:00:00|        2012| 275.1090731349142|efs_high_ldv|\n",
      "|   CA|                     2036|phev_pickup|2012-04-26 16:00:00|        2012|303.16233773326866|efs_high_ldv|\n",
      "|   CA|                     2036|phev_pickup|2012-05-31 14:00:00|        2012|200.52595789310362|efs_high_ldv|\n",
      "|   CA|                     2036|phev_pickup|2012-06-08 22:00:00|        2012|194.36912422169758|efs_high_ldv|\n",
      "|   CA|                     2036|phev_pickup|2012-11-07 13:00:00|        2012|213.74852081008243|efs_high_ldv|\n",
      "+-----+-------------------------+-----------+-------------------+------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(str(data_dir / dataset_name / \"table.parquet\"))\n",
    "df.createOrReplaceTempView(\"tbl\")\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25c1c29-58d6-42be-a497-a55fa37fabc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------+-----------+-------------------+------------+------------------+------------------+\n",
      "|state|tempo_project_model_years|  subsector|           time_est|weather_2012|             value|          scenario|\n",
      "+-----+-------------------------+-----------+-------------------+------------+------------------+------------------+\n",
      "|   CO|                     2050|bev_compact|2012-01-01 00:00:00|        2012|184.78713143567745|ldv_sales_evs_2035|\n",
      "|   CO|                     2050|bev_compact|2012-01-01 00:00:00|        2012|47.780491590023026|         reference|\n",
      "|   CO|                     2050|bev_compact|2012-01-01 00:00:00|        2012|161.75238932508225|      efs_high_ldv|\n",
      "|   CO|                     2050|bev_compact|2012-01-01 01:00:00|        2012|34.985022796630865|         reference|\n",
      "|   CO|                     2050|bev_compact|2012-01-01 01:00:00|        2012|139.11690390121947|ldv_sales_evs_2035|\n",
      "+-----+-------------------------+-----------+-------------------+------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2 = spark.sql(f\"SELECT * FROM tbl WHERE (tempo_project_model_years = 2050) AND (state = 'CO') ORDER BY subsector, time_est LIMIT 5;\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd880e-fbb1-46a1-9d64-2cb436b8c829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
